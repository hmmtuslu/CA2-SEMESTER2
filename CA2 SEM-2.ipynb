{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9175964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"upload_data\").getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.csv(\"/ProjectTweets.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4642809d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  0|1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|  1|1467810672|        Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|                                                                                               is upset that he ...|\n",
      "|  2|1467810917|        Mon Apr 06 22:19:...|NO_QUERY|       mattycus|                                                                                               @Kenichan I dived...|\n",
      "|  3|1467811184|        Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|                                                                                               my whole body fee...|\n",
      "|  4|1467811193|        Mon Apr 06 22:19:...|NO_QUERY|         Karoli|                                                                                               @nationwideclass ...|\n",
      "|  5|1467811372|        Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|                                                                                               @Kwesidei not the...|\n",
      "|  6|1467811592|        Mon Apr 06 22:20:...|NO_QUERY|        mybirch|                                                                                                        Need a hug |\n",
      "|  7|1467811594|        Mon Apr 06 22:20:...|NO_QUERY|           coZZ|                                                                                               @LOLTrish hey  lo...|\n",
      "|  8|1467811795|        Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|                                                                                               @Tatiana_K nope t...|\n",
      "|  9|1467812025|        Mon Apr 06 22:20:...|NO_QUERY|        mimismo|                                                                                               @twittera que me ...|\n",
      "| 10|1467812416|        Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|                                                                                               spring break in p...|\n",
      "| 11|1467812579|        Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|                                                                                               I just re-pierced...|\n",
      "| 12|1467812723|        Mon Apr 06 22:20:...|NO_QUERY|           TLeC|                                                                                               @caregiving I cou...|\n",
      "| 13|1467812771|        Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|                                                                                               @octolinz16 It it...|\n",
      "| 14|1467812784|        Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|                                                                                               @smarrison i woul...|\n",
      "| 15|1467812799|        Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|                                                                                               @iamjazzyfizzle I...|\n",
      "| 16|1467812964|        Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|                                                                                               Hollis' death sce...|\n",
      "| 17|1467813137|        Mon Apr 06 22:20:...|NO_QUERY|       armotley|                                                                                               about to file taxes |\n",
      "| 18|1467813579|        Mon Apr 06 22:20:...|NO_QUERY|     starkissed|                                                                                               @LettyA ahh ive a...|\n",
      "| 19|1467813782|        Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|                                                                                               @FakerPattyPattz ...|\n",
      "| 20|1467813985|        Mon Apr 06 22:20:...|NO_QUERY|         quanvu|                                                                                               @alydesigns i was...|\n",
      "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b60acc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|number|        id|                date|   query|       username|                text|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|     2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|     3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|     4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|     5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|     6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|     7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|     8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|     9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|    10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|    11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|    12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|    13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|    14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|    15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|    16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|    17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "|    18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|    19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "|    20|1467813985|Mon Apr 06 22:20:...|NO_QUERY|         quanvu|@alydesigns i was...|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Spark session start\n",
    "spark = SparkSession.builder.appName(\"AddHeaderToDataFrame\").getOrCreate()\n",
    "\n",
    "columns = [\"number\", \"id\", \"date\", \"query\", \"username\", \"text\"]\n",
    "\n",
    "\n",
    "\n",
    "# Header row\n",
    "header = (\"number\", \"id\", \"date\", \"query\", \"username\", \"text\")\n",
    "\n",
    "# Adding header row\n",
    "df = df.toDF(*header)\n",
    "\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a2b120a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- number: integer (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34878a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:========================>                                 (6 + 8) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1599999 rows and  6 columns in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df.count()} rows and  {len(df.columns)} columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9e40d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  id  date  query  username  text\n",
       "0       0   0     0      0         0     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values check\n",
    "\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "df.select([func.count(func.when(func.isnan(c),c)).alias(c) for c in df.columns]).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03aa47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:==========================>                              (7 + 8) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataframe after dropping the duplicates: 1599999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Duplicates check\n",
    "\n",
    "df = df.dropDuplicates()\n",
    "print(f\"Number of rows in the dataframe after dropping the duplicates: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd751db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('number', 'int'),\n",
       " ('id', 'bigint'),\n",
       " ('date', 'string'),\n",
       " ('query', 'string'),\n",
       " ('username', 'string'),\n",
       " ('text', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Column types\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0231210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols= (\"id\",\"query\",\"username\")\n",
    "df = df.drop(*drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2518659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- number: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ee7affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:============================>                            (7 + 7) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|number|date                        |text                                                                                                                                         |\n",
      "+------+----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|179   |Mon Apr 06 22:31:57 PDT 2009|Staying at a friends house...house sitting, neighbors are SO loud-having a party                                                             |\n",
      "|668   |Mon Apr 06 23:06:23 PDT 2009|i dont want to believe what im reading...buu,so sad                                                                                          |\n",
      "|747   |Mon Apr 06 23:11:06 PDT 2009|Have an invite for &quot;Healthy Dining&quot; session at Ashok Hotel today with Exec Chef R.Chopra but damn workload - will have to skip it! |\n",
      "|1175  |Mon Apr 06 23:42:58 PDT 2009|@amyserrata he wrote most of the album, but ironically, the singles he did not write                                                         |\n",
      "|1251  |Mon Apr 06 23:47:50 PDT 2009|@aniita_0517 Yes i did. That's a sad topic for me! haha... I am not going to the concert... It's very far and probably very expensive        |\n",
      "+------+----------------------------+---------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7005cfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==============>                                         (4 + 11) / 15]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1599999 rows and  3 columns in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"There are {df.count()} rows and  {len(df.columns)} columns in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb4f6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9cc030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hduser/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "text_cleaning_re = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e68f010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(text_cleaning_re, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "570ac217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1 µs, total: 1 µs\n",
      "Wall time: 2.62 µs\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType,FloatType\n",
    "\n",
    "%time\n",
    "clean_text = func.udf(lambda x: preprocess(x), StringType())\n",
    "df = df.withColumn('text_cleaned',clean_text(func.col(\"text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcbf286c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|number|                date|                text|        text_cleaned|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|   179|Mon Apr 06 22:31:...|Staying at a frie...|staying friends h...|\n",
      "|   668|Mon Apr 06 23:06:...|i dont want to be...|dont want believe...|\n",
      "|   747|Mon Apr 06 23:11:...|Have an invite fo...|invite quot healt...|\n",
      "|  1175|Mon Apr 06 23:42:...|@amyserrata he wr...|wrote album ironi...|\n",
      "|  1251|Mon Apr 06 23:47:...|@aniita_0517 Yes ...|yes sad topic hah...|\n",
      "|  1289|Mon Apr 06 23:50:...|@heatherlibby  Oh...|oh well seems lik...|\n",
      "|  1438|Tue Apr 07 00:01:...|Oh, and it's offi...|oh officially bir...|\n",
      "|  1919|Tue Apr 07 00:36:...|my facebook is Fu...|     facebook fucked|\n",
      "|  2582|Tue Apr 07 01:28:...|          need hugs |           need hugs|\n",
      "|  2613|Tue Apr 07 01:31:...|is supposed to wo...|supposed work uni...|\n",
      "|  2800|Tue Apr 07 01:46:...|@ThomasGudgeon We...|well yes shame ge...|\n",
      "|  3568|Tue Apr 07 02:48:...|@alessandrod sadn...|sadness please ke...|\n",
      "|  3621|Tue Apr 07 02:52:...|so tomorrow/today...|tomorrow today fi...|\n",
      "|  3943|Tue Apr 07 03:17:...|wish i was going ...|wish going melbou...|\n",
      "|  4338|Tue Apr 07 03:46:...|one of my teacher...|one teachers died...|\n",
      "|  4512|Tue Apr 07 04:00:...|Watched a movie.....|watched movie fee...|\n",
      "|  4784|Tue Apr 07 04:21:...|Shame processing ...|shame processing ...|\n",
      "|  4839|Tue Apr 07 04:24:...|@seishinseii Tell...|tell hence hate s...|\n",
      "|  5048|Tue Apr 07 04:39:...|&quot;April SNOW ...|quot april snow s...|\n",
      "|  5121|Tue Apr 07 04:46:...|Mornin twitterlin...|mornin twitterlin...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0986efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39b970e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eac0365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 23:53:36,661 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:38,450 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:38,477 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:38,678 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:38,699 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:38,970 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:39,028 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:39,096 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:39,100 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2023-10-30 23:53:39,138 WARN expressions.RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "Cannot resolve column name \"label\" among (number, date, text_cleaned)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6696/3865123573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1600\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwc\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1634\u001b[0m         \"\"\"\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot resolve column name \"label\" among (number, date, text_cleaned)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1152 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_counts = df.groupBy(\"text_cleaned\").count().toPandas()\n",
    "\n",
    "plt.figure(figsize = (20,16)) \n",
    "wc = WordCloud(max_words = 2000 , width = 1600 , height = 900).generate(\" \".join(df[df[\"label\"]==1.0].text_cleaned))\n",
    "plt.imshow(wc , interpolation = 'bilinear')\n",
    "\n",
    "\n",
    "#wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(dict(zip(word_counts['text_cleaned'], word_counts['count'])))\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6cdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
